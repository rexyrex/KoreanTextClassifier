{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri projemize dahil ediyoruz.\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class oranlarımızı hesaplıyoruz\n",
    "# ÖRN N = 4 Yes = 3 No = 1\n",
    "# P(Yes) = 3/4, P(No) = 1/4\n",
    "def labelPredictions(Y):\n",
    "    # Key-value şeklinde tanımlamak için boş bir list tanımlıyoruz\n",
    "    labels = {}\n",
    "    \n",
    "    # Toplam example sayımızı öğreniyoruz\n",
    "    total = len(Y)\n",
    "    \n",
    "    # Her sınıf stününü gezip sayılarını alıyoruz\n",
    "    for label in Y:            \n",
    "        if label in labels:\n",
    "            labels[label] += 1\n",
    "        else:\n",
    "            labels[label] = 1\n",
    "    \n",
    "    # Her label'in oranını hesaplıyoruz.\n",
    "    for i in labels:\n",
    "        val = labels[i]\n",
    "\n",
    "        labels[i] = val / total;\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Parametre olarak alınınan string cümlenin içindeki kelimelerin\n",
    "# harflerini küçülterek alıyoruz.\n",
    "def split_words(sentence):\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    words = list(map(lambda x:x.lower(),words))\n",
    "\n",
    "    return words\n",
    "\n",
    "# Parametre olarak alınan cümlenin içindeki kelimeri\n",
    "# benzersiz bir şekilde alıp yine aynı kelimenin\n",
    "# cümle içinde kaç defa kullanıldığı bilgisi ile birlikte alıyoruz.\n",
    "def split_words_unique(sentence):\n",
    "    words = split_words(sentence)\n",
    "\n",
    "    _words = {}\n",
    "\n",
    "    for w in words:\n",
    "        if w not in _words:\n",
    "            _words[w] = 1\n",
    "        else:\n",
    "            _words[w] += 1\n",
    "\n",
    "    return _words\n",
    "\n",
    "# Vocabulary değerini hesaplıyoruz\n",
    "def calculateVocabulary(X):\n",
    "    amount = 0\n",
    "    stack = []\n",
    "\n",
    "    for sentence in X:\n",
    "        words = split_words(sentence)\n",
    "        \n",
    "\n",
    "        for w in words:\n",
    "            if w not in stack:\n",
    "                stack.append(w)\n",
    "                amount += 1\n",
    "\n",
    "    return amount\n",
    "\n",
    "# Kelime sayısını hesaplıyoruz\n",
    "def determineWordsCount(X):\n",
    "    count = 0\n",
    "\n",
    "    for sentence in X:\n",
    "        words = split_words(sentence)\n",
    "\n",
    "        for w in words:\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Sınıf içindeki kelime sayısını alıyoruz\n",
    "# ÖRN: P(Chinese|Yes) = 5 , P(Tokyo|Yes) = 0\n",
    "def getWordCountInClass(payload,word,c):\n",
    "    df = dataFrameForClass(payload,c)\n",
    "\n",
    "    sentences = df[payload['f_text']]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = split_words(sentence)\n",
    "\n",
    "        for w in words:\n",
    "            if w == word:\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Belirli bir sınıfa ait data frame alıyoruz.\n",
    "# ÖRN: Sadece 'Yes' sınıfına ait text ve label data frame dönecektir.\n",
    "def dataFrameForClass(payload,c):\n",
    "    return payload['X'].loc[payload['X'][payload['f_label']] == c]\n",
    "\n",
    "# Spesifik olarak belirlnen sınıfa ait kelime sayısın verir.\n",
    "def getWordsCount(payload,c):\n",
    "    df = dataFrameForClass(payload,c)\n",
    "\n",
    "    return determineWordsCount(df[payload['f_text']])\n",
    "\n",
    "# Mödelimizi ayarlıyoruz ve gerekli parametreleri bir\n",
    "# list olarak geri alıyoruz\n",
    "def fit(X,Y,f_text = 'sentence',f_label = 'label'):\n",
    "\n",
    "    payload = {};\n",
    "    \n",
    "    # Toplam sınıf sayımızı alıyoruz\n",
    "    payload['classes'] = set(Y)\n",
    "    # Class oranlarımızı alıyoruz\n",
    "    # P(Sport) = 2 / 5 P(Not Sport) = 3 / 5\n",
    "    payload['predictions'] = labelPredictions(Y)\n",
    "    # Vocabulary değerini alıyoruz\n",
    "    payload['vocabulary'] = calculateVocabulary(X[f_text])\n",
    "    \n",
    "    # Diğer veri modellerini kullanmak için\n",
    "    # veri listimize kaydediyoruz\n",
    "    payload['X'] = X\n",
    "    payload['Y'] = Y\n",
    "    payload['f_text'] = f_text\n",
    "    payload['f_label'] = f_label\n",
    "\n",
    "    return payload\n",
    "\n",
    "# Tahminleme işlemlerini gerçekleştiriyoruz\n",
    "def predict(payload,text):\n",
    "    # Cümle içindeki benzersiz kelimeleri alıyoruz\n",
    "    words = split_words_unique(text)\n",
    "    \n",
    "    m_estimate = {}\n",
    "    \n",
    "    # M-Estimate hesaplaması yapıyoruz\n",
    "    for c in payload['classes']:\n",
    "        n = getWordsCount(payload,c)\n",
    "\n",
    "        m_estimate[c] = {}\n",
    "\n",
    "        for word in words:\n",
    "            force = words[word]\n",
    "\n",
    "            n_c = getWordCountInClass(payload,word,c)\n",
    "\n",
    "            # P(d|c) = (n_c + 1) / (n + vocabulary)\n",
    "            _estimate = (n_c + 1) / (n + payload['vocabulary'])\n",
    "            \n",
    "            _estimate = math.pow(_estimate,force)\n",
    "\n",
    "            m_estimate[c][word] = _estimate\n",
    "\n",
    "    tags = {}\n",
    "    \n",
    "    # Hesaplanan herbir class değerlerine göre hesaplama yapıp bunu\n",
    "    # 'tags' objesine aktarıyoruz\n",
    "    # ÖRN: P(d|Yes) = 0,0003 --- P(d|No) = 0,0001\n",
    "    for c in payload['predictions']:\n",
    "        p = payload['predictions'][c]\n",
    "\n",
    "        m = np.prod(list(m_estimate[c].values()))\n",
    "\n",
    "        final = m * p\n",
    "\n",
    "        tags[c] = final\n",
    "        \n",
    "    # print(tags)\n",
    "    \n",
    "        \n",
    "    # Son olarak bulunan etiketlerin arasında\n",
    "    # en yüksek değere sahip etiketi geriye dönderiyoruz.\n",
    "    # Bu şekilde label değerimiz ortaya çıkmış oluyor\n",
    "    return max(tags,key= lambda x: tags[x])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E68': 1.1208127826648813e-07, 'E32': 1.2843289489702288e-07, 'E50': 1.0175598832855088e-07, 'E67': 1.1156239928820677e-07, 'E33': 1.0122764633229616e-07, 'E24': 1.305255408069496e-07, 'E17': 1.0838175327588178e-07, 'E12': 1.0384250494354629e-07, 'E27': 1.1491585828097071e-07, 'E42': 1.0877522273402433e-07, 'E52': 1.028945325659383e-07, 'E55': 1.0679436846959813e-07, 'E35': 1.1268621701092414e-07, 'E10': 1.2705644276776926e-07, 'E31': 1.2167509939122202e-07, 'E28': 1.0622047385711334e-07, 'E36': 1.0259571720555082e-07, 'E25': 1.0078476590391041e-07, 'E65': 9.66004903150907e-08, 'E58': 1.1195632748509463e-07, 'E26': 9.533509202042995e-08, 'E16': 9.967312959701058e-08, 'E59': 1.1006914442882218e-07, 'E37': 1.5315655759048925e-07, 'E38': 1.0593239329851243e-07, 'E44': 1.1607042177791072e-07, 'E40': 1.0651184432344817e-07, 'E30': 1.1364879528708967e-07, 'E18': 1.1466581412552542e-07, 'E60': 1.1546648094439027e-07, 'E13': 1.2683430014302295e-07, 'E34': 1.0785601545062305e-07, 'E29': 1.0419329825614705e-07, 'E22': 1.065533157565951e-07, 'E57': 9.730364226010568e-08, 'E47': 1.0844174062453623e-07, 'E64': 1.1335264727166021e-07, 'E56': 1.1147273834855273e-07, 'E49': 9.901770177027752e-08, 'E51': 9.184462126911993e-08, 'E48': 1.1299152406187252e-07, 'E69': 1.0265215828230073e-07, 'E53': 1.0071097379324176e-07, 'E14': 8.912284355799424e-08, 'E63': 1.1627827122926722e-07, 'E41': 9.805677563249959e-08, 'E61': 1.1034327987688796e-07, 'E39': 1.0379143455244784e-07, 'E21': 1.1608914571423646e-07, 'E20': 1.1392223014425104e-07, 'E62': 1.0773380154561174e-07, 'E45': 1.0252892981287806e-07, 'E23': 1.1198855906168325e-07, 'E11': 1.1251616454297e-07, 'E19': 1.0816831949233247e-07, 'E43': 1.121682169878317e-07, 'E54': 9.509458124031337e-08, 'E46': 9.886539970438548e-08, 'E66': 9.96725736579511e-08, 'E15': 1.0504412586849471e-07}\n",
      "E37\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed_train.csv')\n",
    "\n",
    "payload = fit(df,df['label'])\n",
    "\n",
    "label = predict(payload,\"안녕하세요\")\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E1': 3.0752234765410644e-18, 'E2': 1.0487684045734952e-17, 'E3': 3.62003720736254e-18, 'E5': 5.097271576057071e-18, 'E4': 1.0430828573329226e-17, 'E6': 2.379072591221906e-18}\n",
      "E2\n"
     ]
    }
   ],
   "source": [
    "label = predict(payload,\"그렇게 말하니까 마음 아프네\")\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhkim/anaconda3/envs/rex_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_test_small = pd.read_csv('processed_test.csv', error_bad_lines=False, engine=\"python\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'E68': 1.64637662003396e-18, 'E32': 1.4974739300123283e-17, 'E50': 4.805107284820232e-19, 'E67': 5.855451607022883e-19, 'E33': 1.807673808587963e-18, 'E24': 3.4074008937283977e-17, 'E17': 1.6024328109755085e-18, 'E12': 7.629795946449875e-18, 'E27': 2.6675350839749395e-18, 'E42': 6.678595493444241e-19, 'E52': 1.4452839415304292e-18, 'E55': 1.3287772320421486e-18, 'E35': 2.183728712743998e-18, 'E10': 2.6200434849098565e-18, 'E31': 4.082031302323454e-18, 'E28': 2.9118951805762986e-18, 'E36': 1.4644343686800064e-18, 'E25': 3.1782306784610323e-18, 'E65': 5.066565280438841e-19, 'E58': 1.763416899049605e-18, 'E26': 3.9894666000481627e-19, 'E16': 1.3439455483065635e-18, 'E59': 2.5461323813814137e-18, 'E37': 1.2557264350778259e-17, 'E38': 1.906032698327048e-18, 'E44': 2.0915456459578698e-18, 'E40': 3.4433991143061276e-18, 'E30': 4.3342875329303784e-18, 'E18': 2.79175967725641e-18, 'E60': 1.2054841653131892e-18, 'E13': 7.160574115291401e-18, 'E34': 9.784595691127184e-18, 'E29': 1.449986794426551e-18, 'E22': 1.983305681135035e-18, 'E57': 1.7938076066090836e-19, 'E47': 3.5570691723894176e-18, 'E64': 1.9193996054732524e-18, 'E56': 5.571060726043841e-19, 'E49': 2.656729067123157e-18, 'E51': 2.0252886851395683e-18, 'E48': 7.916961571387254e-18, 'E69': 3.5193734371744673e-19, 'E53': 6.5691172613042585e-18, 'E14': 1.3726906885282275e-18, 'E63': 1.966230163045375e-18, 'E41': 6.312733141251924e-19, 'E61': 1.8520067513310645e-18, 'E39': 1.5994789108853417e-18, 'E21': 1.6182406065199956e-18, 'E20': 6.01408809122869e-18, 'E62': 1.6846719855899227e-19, 'E45': 2.279083433353086e-18, 'E23': 7.44902240275448e-18, 'E11': 5.275216961932431e-18, 'E19': 1.966654340824137e-18, 'E43': 3.734605502684821e-18, 'E54': 2.2473218901824556e-19, 'E46': 9.57910198863166e-19, 'E66': 5.448148740765261e-19, 'E15': 1.6259281720106052e-18}\n",
      "1\n",
      "{'E68': 1.098260651067994e-30, 'E32': 4.347912686867747e-30, 'E50': 8.22936344062197e-32, 'E67': 4.358721789580724e-31, 'E33': 2.027520934249653e-30, 'E24': 2.324674855095817e-28, 'E17': 9.902017762456848e-30, 'E12': 7.631997700581411e-30, 'E27': 8.114523672845231e-28, 'E42': 1.2427867504533094e-28, 'E52': 1.4866685532605557e-30, 'E55': 8.173491624969984e-30, 'E35': 2.0247172572110934e-30, 'E10': 4.860911248400468e-29, 'E31': 3.1243499091507007e-30, 'E28': 5.780349547212271e-29, 'E36': 2.9697336497446143e-31, 'E25': 9.226122855819188e-29, 'E65': 1.7853087625325482e-31, 'E58': 6.212255274263179e-30, 'E26': 2.2979991278768586e-30, 'E16': 2.1559104397348328e-30, 'E59': 1.0894919468247964e-29, 'E37': 1.1799923931115997e-29, 'E38': 8.158142911960301e-32, 'E44': 7.525453286934377e-29, 'E40': 2.1904094311347522e-29, 'E30': 1.052851947579033e-30, 'E18': 1.2326451834398528e-29, 'E60': 3.487455060888901e-30, 'E13': 4.003435006800905e-30, 'E34': 9.418483556329402e-30, 'E29': 7.212607536619568e-29, 'E22': 2.0149049180153272e-27, 'E57': 4.1966314100026245e-31, 'E47': 3.251109448409682e-30, 'E64': 3.0486223060983547e-31, 'E56': 3.928728281895244e-31, 'E49': 9.523433377894879e-29, 'E51': 5.924650024323451e-32, 'E48': 8.764176374760976e-29, 'E69': 1.524322649112097e-32, 'E53': 3.0828680175232903e-29, 'E14': 4.87351016639004e-31, 'E63': 6.010380279568296e-32, 'E41': 2.024460876338114e-31, 'E61': 1.9089296767710357e-32, 'E39': 3.017910658219586e-32, 'E21': 6.780025725551835e-30, 'E20': 2.043564483575346e-27, 'E62': 3.859874878103782e-32, 'E45': 1.0970219637713856e-29, 'E23': 4.771753546805183e-29, 'E11': 2.392423634222325e-30, 'E19': 8.13050366869911e-31, 'E43': 1.1658719454448639e-30, 'E54': 3.3642653730850944e-31, 'E46': 9.077121756029034e-30, 'E66': 4.5438626827404424e-32, 'E15': 6.865223982777785e-32}\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_717437/818939074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_717437/890983878.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(payload, text)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mn_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetWordCountInClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# P(d|c) = (n_c + 1) / (n + vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_717437/890983878.py\u001b[0m in \u001b[0;36mgetWordCountInClass\u001b[0;34m(payload, word, c)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_717437/890983878.py\u001b[0m in \u001b[0;36msplit_words\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^\\w]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_717437/890983878.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^\\w]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0;\n",
    "incorrect = 0;\n",
    "\n",
    "incMap = {}\n",
    "incMapTwo = {}\n",
    "\n",
    "for index, row in df_test_small.iterrows():\n",
    "    print(str(index))\n",
    "    label = row['label']\n",
    "    sentence = row['sentence']\n",
    "    est = predict(payload,sentence)\n",
    "    if(est == label):\n",
    "        correct+=1\n",
    "    else:\n",
    "        incorrect+=1\n",
    "        if(label in incMap):\n",
    "            incMap[label] = incMap[label] + 1\n",
    "        else:\n",
    "            incMap[label] = 1    \n",
    "        if(est in incMapTwo):\n",
    "            incMapTwo[est] = incMapTwo[est] + 1\n",
    "        else:\n",
    "            incMapTwo[est] = 1\n",
    "        # print(\"Estimated LABEL: \" + getReadableClass(est))\n",
    "        # print(\"Correct LABEL: \" + getReadableClass(label))\n",
    "        # print(\"WRONG : \" + sentence)\n",
    "\n",
    "for elem in incMap:\n",
    "    print(elem + \" : \" + str(incMap[elem]*100/incorrect))\n",
    "\n",
    "print(\"========================\")\n",
    "    \n",
    "for elemTwo in incMapTwo:\n",
    "    print(elemTwo + \" : \" + str(incMapTwo[elemTwo]*100/incorrect))\n",
    "        \n",
    "print(\"Accuracy : \" + str(correct/(correct+incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
